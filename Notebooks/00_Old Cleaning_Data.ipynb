{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ DRAFT\n",
    "\n",
    "Before diving into the analysis, a thorough data cleaning process was performed to ensure the dataset is accurate and ready for use. Cleaning the data is a crucial step to ensure the analysis is based on reliable information and free of inconsistencies.8\n",
    "\n",
    "### Key Cleaning Steps:\n",
    "\n",
    "1. **Handling Missing Values**:\n",
    "   - We addressed missing or incomplete data in critical columns such as `State`, `Age`, and `Sex`. This ensures that the dataset contains only rows with the necessary information for analysis.\n",
    "\n",
    "2. **Removing Invalid Entries** üèõÔ∏è:\n",
    "   - In the `State` column, we validated that all entries correspond to valid U.S. state abbreviations. Any rows with incorrect or missing state information were removed.\n",
    "\n",
    "3. **Filtering Out Unknown Values** üßë‚Äçü§ù‚Äçüßë:\n",
    "   - A significant number of entries had \"Unknown\" in the `Sex` column. To avoid potential biases, these entries were removed, leaving only records with valid male or female identifiers.\n",
    "\n",
    "4. **Dropping Irrelevant Columns** ‚úÇÔ∏è:\n",
    "   - Several columns that were not relevant to our analysis (e.g., unnecessary time or administrative data) were removed to streamline the dataset and focus on the most useful information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the VAERS Data (Demographics and Event Information)\n",
    "vaers_data = pd.read_csv('VAERSDATA.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAERS_ID</th>\n",
       "      <th>RECVDATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>AGE_YRS</th>\n",
       "      <th>CAGE_YR</th>\n",
       "      <th>CAGE_MO</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RPT_DATE</th>\n",
       "      <th>SYMPTOM_TEXT</th>\n",
       "      <th>DIED</th>\n",
       "      <th>...</th>\n",
       "      <th>CUR_ILL</th>\n",
       "      <th>HISTORY</th>\n",
       "      <th>PRIOR_VAX</th>\n",
       "      <th>SPLTTYPE</th>\n",
       "      <th>FORM_VERS</th>\n",
       "      <th>TODAYS_DATE</th>\n",
       "      <th>BIRTH_DEFECT</th>\n",
       "      <th>OFC_VISIT</th>\n",
       "      <th>ER_ED_VISIT</th>\n",
       "      <th>ALLERGIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>902418</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NJ</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patient experienced mild numbness traveling fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>902440</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>AZ</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C/O Headache</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>902446</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>WV</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>felt warm, hot and face and ears were red and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>Hypertension, sleep apnea, hypothyroidism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrast Dye IV contrast, shellfish, strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>902464</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>LA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>within 15 minutes progressive light-headedness...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>902465</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>AR</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pt felt wave come over body @ 1218 starting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Bronchitis, finished prednisone on 12-13-20</td>\n",
       "      <td>hypertension, fibromyalgia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biaxin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAERS_ID    RECVDATE STATE  AGE_YRS  CAGE_YR  CAGE_MO SEX RPT_DATE  \\\n",
       "0    902418  12/15/2020    NJ     56.0     56.0      NaN   F      NaN   \n",
       "1    902440  12/15/2020    AZ     35.0     35.0      NaN   F      NaN   \n",
       "2    902446  12/15/2020    WV     55.0     55.0      NaN   F      NaN   \n",
       "3    902464  12/15/2020    LA     42.0     42.0      NaN   M      NaN   \n",
       "4    902465  12/15/2020    AR     60.0     60.0      NaN   F      NaN   \n",
       "\n",
       "                                        SYMPTOM_TEXT DIED  ...  \\\n",
       "0  Patient experienced mild numbness traveling fr...  NaN  ...   \n",
       "1                                       C/O Headache  NaN  ...   \n",
       "2  felt warm, hot and face and ears were red and ...  NaN  ...   \n",
       "3  within 15 minutes progressive light-headedness...  NaN  ...   \n",
       "4  Pt felt wave come over body @ 1218 starting in...  NaN  ...   \n",
       "\n",
       "                                       CUR_ILL  \\\n",
       "0                                         none   \n",
       "1                                          NaN   \n",
       "2                                         none   \n",
       "3                                         none   \n",
       "4  Bronchitis, finished prednisone on 12-13-20   \n",
       "\n",
       "                                     HISTORY PRIOR_VAX SPLTTYPE  FORM_VERS  \\\n",
       "0                                       none       NaN      NaN          2   \n",
       "1                                        NaN       NaN      NaN          2   \n",
       "2  Hypertension, sleep apnea, hypothyroidism       NaN      NaN          2   \n",
       "3                                       none       NaN      NaN          2   \n",
       "4                 hypertension, fibromyalgia       NaN      NaN          2   \n",
       "\n",
       "  TODAYS_DATE BIRTH_DEFECT OFC_VISIT ER_ED_VISIT  \\\n",
       "0  12/15/2020          NaN       NaN         NaN   \n",
       "1  12/15/2020          NaN       NaN         NaN   \n",
       "2  12/15/2020          NaN       NaN         NaN   \n",
       "3  12/15/2020          NaN       NaN           Y   \n",
       "4  12/15/2020          NaN       NaN         NaN   \n",
       "\n",
       "                                         ALLERGIES  \n",
       "0                                             none  \n",
       "1                                              NaN  \n",
       "2  Contrast Dye IV contrast, shellfish, strawberry  \n",
       "3                                             none  \n",
       "4                                           Biaxin  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaers_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1012894 entries, 0 to 1012893\n",
      "Data columns (total 35 columns):\n",
      " #   Column        Non-Null Count    Dtype  \n",
      "---  ------        --------------    -----  \n",
      " 0   VAERS_ID      1012894 non-null  int64  \n",
      " 1   RECVDATE      1012894 non-null  object \n",
      " 2   STATE         842425 non-null   object \n",
      " 3   AGE_YRS       909608 non-null   float64\n",
      " 4   CAGE_YR       809314 non-null   float64\n",
      " 5   CAGE_MO       5374 non-null     float64\n",
      " 6   SEX           1012894 non-null  object \n",
      " 7   RPT_DATE      1130 non-null     object \n",
      " 8   SYMPTOM_TEXT  1011423 non-null  object \n",
      " 9   DIED          18951 non-null    object \n",
      " 10  DATEDIED      16828 non-null    object \n",
      " 11  L_THREAT      15197 non-null    object \n",
      " 12  ER_VISIT      144 non-null      object \n",
      " 13  HOSPITAL      90081 non-null    object \n",
      " 14  HOSPDAYS      53040 non-null    float64\n",
      " 15  X_STAY        505 non-null      object \n",
      " 16  DISABLE       18274 non-null    object \n",
      " 17  RECOVD        882224 non-null   object \n",
      " 18  VAX_DATE      938970 non-null   object \n",
      " 19  ONSET_DATE    915481 non-null   object \n",
      " 20  NUMDAYS       876293 non-null   float64\n",
      " 21  LAB_DATA      323017 non-null   object \n",
      " 22  V_ADMINBY     1012894 non-null  object \n",
      " 23  V_FUNDBY      1204 non-null     object \n",
      " 24  OTHER_MEDS    467633 non-null   object \n",
      " 25  CUR_ILL       260920 non-null   object \n",
      " 26  HISTORY       482751 non-null   object \n",
      " 27  PRIOR_VAX     47095 non-null    object \n",
      " 28  SPLTTYPE      314267 non-null   object \n",
      " 29  FORM_VERS     1012894 non-null  int64  \n",
      " 30  TODAYS_DATE   1001980 non-null  object \n",
      " 31  BIRTH_DEFECT  613 non-null      object \n",
      " 32  OFC_VISIT     199491 non-null   object \n",
      " 33  ER_ED_VISIT   118932 non-null   object \n",
      " 34  ALLERGIES     372286 non-null   object \n",
      "dtypes: float64(5), int64(2), object(28)\n",
      "memory usage: 270.5+ MB\n"
     ]
    }
   ],
   "source": [
    "vaers_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VAERS_ID', 'RECVDATE', 'STATE', 'AGE_YRS', 'CAGE_YR', 'CAGE_MO', 'SEX',\n",
       "       'RPT_DATE', 'SYMPTOM_TEXT', 'DIED', 'DATEDIED', 'L_THREAT', 'ER_VISIT',\n",
       "       'HOSPITAL', 'HOSPDAYS', 'X_STAY', 'DISABLE', 'RECOVD', 'VAX_DATE',\n",
       "       'ONSET_DATE', 'NUMDAYS', 'LAB_DATA', 'V_ADMINBY', 'V_FUNDBY',\n",
       "       'OTHER_MEDS', 'CUR_ILL', 'HISTORY', 'PRIOR_VAX', 'SPLTTYPE',\n",
       "       'FORM_VERS', 'TODAYS_DATE', 'BIRTH_DEFECT', 'OFC_VISIT', 'ER_ED_VISIT',\n",
       "       'ALLERGIES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaers_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of VAERS DataFrame after dropping irrelevant columns: (1012894, 17)\n"
     ]
    }
   ],
   "source": [
    "# List of columns to drop based on the analysis\n",
    "columns_to_drop = [\n",
    "    'CAGE_YR', 'CAGE_MO', 'RPT_DATE', 'HOSPDAYS', 'X_STAY', 'NUMDAYS', \n",
    "    'LAB_DATA', 'V_FUNDBY', 'OTHER_MEDS', 'SPLTTYPE', 'FORM_VERS', \n",
    "    'TODAYS_DATE', 'OFC_VISIT', 'ER_ED_VISIT', 'V_ADMINBY','HISTORY','ER_VISIT','CUR_ILL'\n",
    "]\n",
    "\n",
    "# Drop the unnecessary columns from the DataFrame\n",
    "vaers_data_cleaned = vaers_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the shape of the cleaned DataFrame to verify the result\n",
    "print(\"Shape of VAERS DataFrame after dropping irrelevant columns:\", vaers_data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAERS_ID</th>\n",
       "      <th>RECVDATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>AGE_YRS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SYMPTOM_TEXT</th>\n",
       "      <th>DIED</th>\n",
       "      <th>DATEDIED</th>\n",
       "      <th>L_THREAT</th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>DISABLE</th>\n",
       "      <th>RECOVD</th>\n",
       "      <th>VAX_DATE</th>\n",
       "      <th>ONSET_DATE</th>\n",
       "      <th>PRIOR_VAX</th>\n",
       "      <th>BIRTH_DEFECT</th>\n",
       "      <th>ALLERGIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>902418</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NJ</td>\n",
       "      <td>56.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Patient experienced mild numbness traveling fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>902440</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>AZ</td>\n",
       "      <td>35.0</td>\n",
       "      <td>F</td>\n",
       "      <td>C/O Headache</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>902446</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>WV</td>\n",
       "      <td>55.0</td>\n",
       "      <td>F</td>\n",
       "      <td>felt warm, hot and face and ears were red and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrast Dye IV contrast, shellfish, strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>902464</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>LA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>M</td>\n",
       "      <td>within 15 minutes progressive light-headedness...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>902465</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>AR</td>\n",
       "      <td>60.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Pt felt wave come over body @ 1218 starting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biaxin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAERS_ID    RECVDATE STATE  AGE_YRS SEX  \\\n",
       "0    902418  12/15/2020    NJ     56.0   F   \n",
       "1    902440  12/15/2020    AZ     35.0   F   \n",
       "2    902446  12/15/2020    WV     55.0   F   \n",
       "3    902464  12/15/2020    LA     42.0   M   \n",
       "4    902465  12/15/2020    AR     60.0   F   \n",
       "\n",
       "                                        SYMPTOM_TEXT DIED DATEDIED L_THREAT  \\\n",
       "0  Patient experienced mild numbness traveling fr...  NaN      NaN      NaN   \n",
       "1                                       C/O Headache  NaN      NaN      NaN   \n",
       "2  felt warm, hot and face and ears were red and ...  NaN      NaN      NaN   \n",
       "3  within 15 minutes progressive light-headedness...  NaN      NaN      NaN   \n",
       "4  Pt felt wave come over body @ 1218 starting in...  NaN      NaN      NaN   \n",
       "\n",
       "  HOSPITAL DISABLE RECOVD    VAX_DATE  ONSET_DATE PRIOR_VAX BIRTH_DEFECT  \\\n",
       "0      NaN     NaN      Y  12/15/2020  12/15/2020       NaN          NaN   \n",
       "1      NaN     NaN      Y  12/15/2020  12/15/2020       NaN          NaN   \n",
       "2      NaN     NaN      Y  12/15/2020  12/15/2020       NaN          NaN   \n",
       "3      NaN     NaN      Y  12/15/2020  12/15/2020       NaN          NaN   \n",
       "4      NaN     NaN      N  12/15/2020  12/15/2020       NaN          NaN   \n",
       "\n",
       "                                         ALLERGIES  \n",
       "0                                             none  \n",
       "1                                              NaN  \n",
       "2  Contrast Dye IV contrast, shellfish, strawberry  \n",
       "3                                             none  \n",
       "4                                           Biaxin  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaers_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of null values in each column:\n",
      "VAERS_ID              0\n",
      "RECVDATE              0\n",
      "STATE            170469\n",
      "AGE_YRS          103286\n",
      "SEX                   0\n",
      "SYMPTOM_TEXT       1471\n",
      "DIED             993943\n",
      "DATEDIED         996066\n",
      "L_THREAT         997697\n",
      "HOSPITAL         922813\n",
      "DISABLE          994620\n",
      "RECOVD           130670\n",
      "VAX_DATE          73924\n",
      "ONSET_DATE        97413\n",
      "PRIOR_VAX        965799\n",
      "BIRTH_DEFECT    1012281\n",
      "ALLERGIES        640608\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the entire DataFrame\n",
    "null_values = vaers_data_cleaned.isnull().sum()\n",
    "\n",
    "# Display the count of null values for each column\n",
    "print(\"Count of null values in each column:\")\n",
    "print(null_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of VAERS DataFrame after dropping rows with nulls in critical columns: (787806, 17)\n",
      "\n",
      "Remaining missing values in critical columns:\n",
      "VAERS_ID    0\n",
      "STATE       0\n",
      "AGE_YRS     0\n",
      "SEX         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in the critical columns: VAERS_ID, STATE, AGE_YRS, and SEX\n",
    "vaers_data_cleaned = vaers_data_cleaned.dropna(subset=['VAERS_ID', 'STATE', 'AGE_YRS', 'SEX'])\n",
    "\n",
    "# Display the shape of the cleaned DataFrame to verify the result\n",
    "print(\"Shape of VAERS DataFrame after dropping rows with nulls in critical columns:\", vaers_data_cleaned.shape)\n",
    "\n",
    "# Check if there are any remaining null values in those critical columns\n",
    "print(\"\\nRemaining missing values in critical columns:\")\n",
    "print(vaers_data_cleaned[['VAERS_ID', 'STATE', 'AGE_YRS', 'SEX']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of valid U.S. state abbreviations (50 states only)\n",
    "valid_states = [\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS',\n",
    "    'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY',\n",
    "    'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', \n",
    "    'WI', 'WY'\n",
    "]\n",
    "\n",
    "# Filter rows where the STATE column contains valid state abbreviations\n",
    "vaers_data_cleaned = vaers_data_cleaned[vaers_data_cleaned['STATE'].isin(valid_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of VAERS DataFrame after removing 'Unknown' sex entries: (772636, 17)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where SEX is 'U' (Unknown)\n",
    "vaers_data_cleaned = vaers_data_cleaned[vaers_data_cleaned['SEX'] != 'U']\n",
    "\n",
    "# Display the shape of the DataFrame after removing 'Unknown' sex entries\n",
    "print(\"Shape of VAERS DataFrame after removing 'Unknown' sex entries:\", vaers_data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX column value counts:\n",
      "SEX\n",
      "F    522793\n",
      "M    249843\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the value counts for the SEX column to see how many \"unknown\" values exist\n",
    "sex_value_counts = vaers_data_cleaned['SEX'].value_counts(dropna=False)\n",
    "print(\"SEX column value counts:\")\n",
    "print(sex_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for the DIED column after transformation:\n",
      "DIED\n",
      "0    760514\n",
      "1     12122\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert the DIED column to binary: 1 for 'Y', 0 for empty or null\n",
    "vaers_data_cleaned['DIED'] = vaers_data_cleaned['DIED'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "\n",
    "# Check the result of the transformation\n",
    "print(\"Value counts for the DIED column after transformation:\")\n",
    "print(vaers_data_cleaned['DIED'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the HOSPITAL column to binary: 1 for 'Y', 0 for empty or null\n",
    "vaers_data_cleaned['HOSPITAL'] = vaers_data_cleaned['HOSPITAL'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "\n",
    "# Convert the DISABLE column to binary: 1 for 'Y', 0 for empty or null\n",
    "vaers_data_cleaned['DISABLE'] = vaers_data_cleaned['DISABLE'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "\n",
    "# Convert the BIRTH_DEFECT column to binary: 1 for 'Y', 0 for empty or null\n",
    "vaers_data_cleaned['BIRTH_DEFECT'] = vaers_data_cleaned['BIRTH_DEFECT'].apply(lambda x: 1 if x == 'Y' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 772636 entries, 0 to 1012886\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   VAERS_ID      772636 non-null  int64  \n",
      " 1   RECVDATE      772636 non-null  object \n",
      " 2   STATE         772636 non-null  object \n",
      " 3   AGE_YRS       772636 non-null  float64\n",
      " 4   SEX           772636 non-null  object \n",
      " 5   SYMPTOM_TEXT  771639 non-null  object \n",
      " 6   DIED          772636 non-null  int64  \n",
      " 7   DATEDIED      11649 non-null   object \n",
      " 8   L_THREAT      13776 non-null   object \n",
      " 9   HOSPITAL      772636 non-null  int64  \n",
      " 10  DISABLE       772636 non-null  int64  \n",
      " 11  RECOVD        695682 non-null  object \n",
      " 12  VAX_DATE      760654 non-null  object \n",
      " 13  ONSET_DATE    744169 non-null  object \n",
      " 14  PRIOR_VAX     44519 non-null   object \n",
      " 15  BIRTH_DEFECT  772636 non-null  int64  \n",
      " 16  ALLERGIES     356508 non-null  object \n",
      "dtypes: float64(1), int64(5), object(11)\n",
      "memory usage: 106.1+ MB\n"
     ]
    }
   ],
   "source": [
    "vaers_data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaers_data_cleaned = vaers_data_cleaned.dropna(subset=['STATE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 772636 entries, 0 to 1012886\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   VAERS_ID      772636 non-null  int64  \n",
      " 1   RECVDATE      772636 non-null  object \n",
      " 2   STATE         772636 non-null  object \n",
      " 3   AGE_YRS       772636 non-null  float64\n",
      " 4   SEX           772636 non-null  object \n",
      " 5   SYMPTOM_TEXT  771639 non-null  object \n",
      " 6   DIED          772636 non-null  int64  \n",
      " 7   DATEDIED      11649 non-null   object \n",
      " 8   L_THREAT      13776 non-null   object \n",
      " 9   HOSPITAL      772636 non-null  int64  \n",
      " 10  DISABLE       772636 non-null  int64  \n",
      " 11  RECOVD        695682 non-null  object \n",
      " 12  VAX_DATE      760654 non-null  object \n",
      " 13  ONSET_DATE    744169 non-null  object \n",
      " 14  PRIOR_VAX     44519 non-null   object \n",
      " 15  BIRTH_DEFECT  772636 non-null  int64  \n",
      " 16  ALLERGIES     356508 non-null  object \n",
      "dtypes: float64(1), int64(5), object(11)\n",
      "memory usage: 106.1+ MB\n"
     ]
    }
   ],
   "source": [
    "vaers_data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAERS_ID    0\n",
      "STATE       0\n",
      "AGE_YRS     0\n",
      "SEX         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Example: Drop rows with missing data in critical columns in VAERS dataset\n",
    "critical_columns_vaers = ['AGE_YRS', 'SEX', 'STATE', 'SYMPTOM_TEXT', 'DIED', 'VAX_DATE']\n",
    "vaers_data_cleaned = vaers_data_cleaned.dropna(subset=critical_columns_vaers)\n",
    "\n",
    "# Similarly, do this for the other datasets, like symptoms and vaccination data\n",
    "\n",
    "print(vaers_data_cleaned[['VAERS_ID', 'STATE', 'AGE_YRS', 'SEX']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in SYMPTOM_TEXT\n",
    "print(vaers_data_cleaned['SYMPTOM_TEXT'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAX_DATE      datetime64[ns]\n",
      "ONSET_DATE    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert VAX_DATE and ONSET_DATE to datetime\n",
    "vaers_data_cleaned['VAX_DATE'] = pd.to_datetime(vaers_data_cleaned['VAX_DATE'], errors='coerce')\n",
    "vaers_data_cleaned['ONSET_DATE'] = pd.to_datetime(vaers_data_cleaned['ONSET_DATE'], errors='coerce')\n",
    "\n",
    "# Verify the conversion\n",
    "print(vaers_data_cleaned[['VAX_DATE', 'ONSET_DATE']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 759664 entries, 0 to 1012886\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   VAERS_ID      759664 non-null  int64         \n",
      " 1   RECVDATE      759664 non-null  object        \n",
      " 2   STATE         759664 non-null  object        \n",
      " 3   AGE_YRS       759664 non-null  float64       \n",
      " 4   SEX           759664 non-null  object        \n",
      " 5   SYMPTOM_TEXT  759664 non-null  object        \n",
      " 6   DIED          759664 non-null  int64         \n",
      " 7   DATEDIED      11576 non-null   object        \n",
      " 8   L_THREAT      13674 non-null   object        \n",
      " 9   HOSPITAL      759664 non-null  int64         \n",
      " 10  DISABLE       759664 non-null  int64         \n",
      " 11  RECOVD        683668 non-null  object        \n",
      " 12  VAX_DATE      759664 non-null  datetime64[ns]\n",
      " 13  ONSET_DATE    736100 non-null  datetime64[ns]\n",
      " 14  PRIOR_VAX     44444 non-null   object        \n",
      " 15  BIRTH_DEFECT  759664 non-null  int64         \n",
      " 16  ALLERGIES     355579 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(5), object(9)\n",
      "memory usage: 104.3+ MB\n"
     ]
    }
   ],
   "source": [
    "vaers_data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAERS_ID</th>\n",
       "      <th>RECVDATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>AGE_YRS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SYMPTOM_TEXT</th>\n",
       "      <th>DIED</th>\n",
       "      <th>DATEDIED</th>\n",
       "      <th>L_THREAT</th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>DISABLE</th>\n",
       "      <th>RECOVD</th>\n",
       "      <th>VAX_DATE</th>\n",
       "      <th>ONSET_DATE</th>\n",
       "      <th>PRIOR_VAX</th>\n",
       "      <th>BIRTH_DEFECT</th>\n",
       "      <th>ALLERGIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>902418</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NJ</td>\n",
       "      <td>56.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Patient experienced mild numbness traveling fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>902440</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>AZ</td>\n",
       "      <td>35.0</td>\n",
       "      <td>F</td>\n",
       "      <td>C/O Headache</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>902446</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>WV</td>\n",
       "      <td>55.0</td>\n",
       "      <td>F</td>\n",
       "      <td>felt warm, hot and face and ears were red and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrast Dye IV contrast, shellfish, strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>902464</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>LA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>M</td>\n",
       "      <td>within 15 minutes progressive light-headedness...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>902465</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>AR</td>\n",
       "      <td>60.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Pt felt wave come over body @ 1218 starting in...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Biaxin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAERS_ID    RECVDATE STATE  AGE_YRS SEX  \\\n",
       "0    902418  12/15/2020    NJ     56.0   F   \n",
       "1    902440  12/15/2020    AZ     35.0   F   \n",
       "2    902446  12/15/2020    WV     55.0   F   \n",
       "3    902464  12/15/2020    LA     42.0   M   \n",
       "4    902465  12/15/2020    AR     60.0   F   \n",
       "\n",
       "                                        SYMPTOM_TEXT  DIED DATEDIED L_THREAT  \\\n",
       "0  Patient experienced mild numbness traveling fr...     0      NaN      NaN   \n",
       "1                                       C/O Headache     0      NaN      NaN   \n",
       "2  felt warm, hot and face and ears were red and ...     0      NaN      NaN   \n",
       "3  within 15 minutes progressive light-headedness...     0      NaN      NaN   \n",
       "4  Pt felt wave come over body @ 1218 starting in...     0      NaN      NaN   \n",
       "\n",
       "   HOSPITAL  DISABLE RECOVD   VAX_DATE ONSET_DATE PRIOR_VAX  BIRTH_DEFECT  \\\n",
       "0         0        0      Y 2020-12-15 2020-12-15       NaN             0   \n",
       "1         0        0      Y 2020-12-15 2020-12-15       NaN             0   \n",
       "2         0        0      Y 2020-12-15 2020-12-15       NaN             0   \n",
       "3         0        0      Y 2020-12-15 2020-12-15       NaN             0   \n",
       "4         0        0      N 2020-12-15 2020-12-15       NaN             0   \n",
       "\n",
       "                                         ALLERGIES  \n",
       "0                                             none  \n",
       "1                                              NaN  \n",
       "2  Contrast Dye IV contrast, shellfish, strawberry  \n",
       "3                                             none  \n",
       "4                                           Biaxin  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaers_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SEX  SEX_BINARY\n",
      "0   F           0\n",
      "1   F           0\n",
      "2   F           0\n",
      "3   M           1\n",
      "4   F           0\n"
     ]
    }
   ],
   "source": [
    "# Convert SEX column to binary: 1 for Male ('M'), 0 for Female ('F')\n",
    "vaers_data_cleaned['SEX_BINARY'] = vaers_data_cleaned['SEX'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# Verify the result\n",
    "print(vaers_data_cleaned[['SEX', 'SEX_BINARY']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'M']\n",
      "  SEX  SEX_BINARY\n",
      "0   F           0\n",
      "1   F           0\n",
      "2   F           0\n",
      "3   M           1\n",
      "4   F           0\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in SEX to confirm the actual values\n",
    "print(vaers_data_cleaned['SEX'].unique())\n",
    "\n",
    "# Convert SEX to binary: 1 for Male ('M'), 0 for Female ('F')\n",
    "# Handle unknown or missing values by assigning them as NaN or 0\n",
    "vaers_data_cleaned['SEX_BINARY'] = vaers_data_cleaned['SEX'].apply(lambda x: 1 if x == 'M' else (0 if x == 'F' else None))\n",
    "\n",
    "# Verify the result\n",
    "print(vaers_data_cleaned[['SEX', 'SEX_BINARY']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX\n",
      "F    514900\n",
      "M    244764\n",
      "Name: count, dtype: int64\n",
      "  SEX  SEX_BINARY\n",
      "0   F           0\n",
      "1   F           0\n",
      "2   F           0\n",
      "3   M           1\n",
      "4   F           0\n",
      "SEX_BINARY\n",
      "0    514900\n",
      "1    244764\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm the distribution of 'SEX' values (should only be 'M' and 'F')\n",
    "print(vaers_data_cleaned['SEX'].value_counts())\n",
    "\n",
    "# Convert SEX to binary: 1 for Male ('M'), 0 for Female ('F')\n",
    "vaers_data_cleaned['SEX_BINARY'] = vaers_data_cleaned['SEX'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# Verify the result\n",
    "print(vaers_data_cleaned[['SEX', 'SEX_BINARY']].head())\n",
    "\n",
    "# Check value counts for the new SEX_BINARY column to confirm the transformation\n",
    "print(vaers_data_cleaned['SEX_BINARY'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VAERS_ID    RECVDATE STATE  AGE_YRS  SEX  \\\n",
      "0    902418  12/15/2020    NJ     56.0    0   \n",
      "1    902440  12/15/2020    AZ     35.0    0   \n",
      "2    902446  12/15/2020    WV     55.0    0   \n",
      "3    902464  12/15/2020    LA     42.0    1   \n",
      "4    902465  12/15/2020    AR     60.0    0   \n",
      "\n",
      "                                        SYMPTOM_TEXT  DIED DATEDIED L_THREAT  \\\n",
      "0  Patient experienced mild numbness traveling fr...     0      NaN      NaN   \n",
      "1                                       C/O Headache     0      NaN      NaN   \n",
      "2  felt warm, hot and face and ears were red and ...     0      NaN      NaN   \n",
      "3  within 15 minutes progressive light-headedness...     0      NaN      NaN   \n",
      "4  Pt felt wave come over body @ 1218 starting in...     0      NaN      NaN   \n",
      "\n",
      "   HOSPITAL  DISABLE RECOVD   VAX_DATE ONSET_DATE PRIOR_VAX  BIRTH_DEFECT  \\\n",
      "0         0        0      Y 2020-12-15 2020-12-15       NaN             0   \n",
      "1         0        0      Y 2020-12-15 2020-12-15       NaN             0   \n",
      "2         0        0      Y 2020-12-15 2020-12-15       NaN             0   \n",
      "3         0        0      Y 2020-12-15 2020-12-15       NaN             0   \n",
      "4         0        0      N 2020-12-15 2020-12-15       NaN             0   \n",
      "\n",
      "                                         ALLERGIES  \n",
      "0                                             none  \n",
      "1                                              NaN  \n",
      "2  Contrast Dye IV contrast, shellfish, strawberry  \n",
      "3                                             none  \n",
      "4                                           Biaxin  \n"
     ]
    }
   ],
   "source": [
    "# Replace the original 'SEX' column with the binary version\n",
    "vaers_data_cleaned['SEX'] = vaers_data_cleaned['SEX_BINARY']\n",
    "\n",
    "# Drop the temporary 'SEX_BINARY' column since it's now stored in 'SEX'\n",
    "vaers_data_cleaned = vaers_data_cleaned.drop(columns=['SEX_BINARY'])\n",
    "\n",
    "# Verify the result\n",
    "print(vaers_data_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min and Max Age after filtering: 0.5 - 100.0\n"
     ]
    }
   ],
   "source": [
    "# Filter age to remove outliers (between 0.5 years and 100 years)\n",
    "vaers_data_cleaned = vaers_data_cleaned[(vaers_data_cleaned['AGE_YRS'] >= 0.5) & (vaers_data_cleaned['AGE_YRS'] <= 100)]\n",
    "\n",
    "# Verify the new age range\n",
    "print(\"Min and Max Age after filtering:\", vaers_data_cleaned['AGE_YRS'].min(), \"-\", vaers_data_cleaned['AGE_YRS'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for RECOVD after binary transformation:\n",
      "RECOVD\n",
      "0    500340\n",
      "1    259062\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for L_THREAT after binary transformation:\n",
      "L_THREAT\n",
      "0    745737\n",
      "1     13665\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert RECOVD to binary: 1 for 'Y', 0 for anything else (including NaN)\n",
    "vaers_data_cleaned['RECOVD'] = vaers_data_cleaned['RECOVD'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "\n",
    "# Convert L_THREAT to binary: 1 for 'Y', 0 for anything else (including NaN)\n",
    "vaers_data_cleaned['L_THREAT'] = vaers_data_cleaned['L_THREAT'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "\n",
    "# Verify the result\n",
    "print(\"Value counts for RECOVD after binary transformation:\")\n",
    "print(vaers_data_cleaned['RECOVD'].value_counts())\n",
    "\n",
    "print(\"\\nValue counts for L_THREAT after binary transformation:\")\n",
    "print(vaers_data_cleaned['L_THREAT'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 759402 entries, 0 to 1012886\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   VAERS_ID      759402 non-null  int64         \n",
      " 1   RECVDATE      759402 non-null  object        \n",
      " 2   STATE         759402 non-null  object        \n",
      " 3   AGE_YRS       759402 non-null  float64       \n",
      " 4   SEX           759402 non-null  int64         \n",
      " 5   SYMPTOM_TEXT  759402 non-null  object        \n",
      " 6   DIED          759402 non-null  int64         \n",
      " 7   DATEDIED      11531 non-null   object        \n",
      " 8   L_THREAT      759402 non-null  int64         \n",
      " 9   HOSPITAL      759402 non-null  int64         \n",
      " 10  DISABLE       759402 non-null  int64         \n",
      " 11  RECOVD        759402 non-null  int64         \n",
      " 12  VAX_DATE      759402 non-null  datetime64[ns]\n",
      " 13  ONSET_DATE    735849 non-null  datetime64[ns]\n",
      " 14  PRIOR_VAX     44439 non-null   object        \n",
      " 15  BIRTH_DEFECT  759402 non-null  int64         \n",
      " 16  ALLERGIES     355456 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(8), object(6)\n",
      "memory usage: 104.3+ MB\n"
     ]
    }
   ],
   "source": [
    "vaers_data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "    RECVDATE\n",
      "0 2020-12-15\n",
      "1 2020-12-15\n",
      "2 2020-12-15\n",
      "3 2020-12-15\n",
      "4 2020-12-15\n"
     ]
    }
   ],
   "source": [
    "# Convert the RECVDATE column to datetime format\n",
    "vaers_data_cleaned['RECVDATE'] = pd.to_datetime(vaers_data_cleaned['RECVDATE'], errors='coerce')\n",
    "\n",
    "# Verify the conversion\n",
    "print(vaers_data_cleaned['RECVDATE'].dtypes)\n",
    "print(vaers_data_cleaned[['RECVDATE']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAERS_ID             0\n",
      "RECVDATE             0\n",
      "STATE                0\n",
      "AGE_YRS              0\n",
      "SEX                  0\n",
      "SYMPTOM_TEXT         0\n",
      "DIED                 0\n",
      "DATEDIED        747871\n",
      "L_THREAT             0\n",
      "HOSPITAL             0\n",
      "DISABLE              0\n",
      "RECOVD               0\n",
      "VAX_DATE             0\n",
      "ONSET_DATE       23553\n",
      "PRIOR_VAX       714963\n",
      "BIRTH_DEFECT         0\n",
      "ALLERGIES       403946\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "print(vaers_data_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAERS_ID             0\n",
      "RECVDATE             0\n",
      "STATE                0\n",
      "AGE_YRS              0\n",
      "SEX                  0\n",
      "SYMPTOM_TEXT         0\n",
      "DIED                 0\n",
      "DATEDIED        747871\n",
      "L_THREAT             0\n",
      "HOSPITAL             0\n",
      "DISABLE              0\n",
      "RECOVD               0\n",
      "VAX_DATE             0\n",
      "ONSET_DATE       23553\n",
      "PRIOR_VAX       714963\n",
      "BIRTH_DEFECT         0\n",
      "ALLERGIES       403946\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where SYMPTOM_TEXT is missing\n",
    "vaers_data_cleaned = vaers_data_cleaned.dropna(subset=['SYMPTOM_TEXT'])\n",
    "\n",
    "# Verify the result\n",
    "print(vaers_data_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sifre\\AppData\\Local\\Temp\\ipykernel_18368\\831549725.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  vaers_data_cleaned['PRIOR_VAX'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\sifre\\AppData\\Local\\Temp\\ipykernel_18368\\831549725.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  vaers_data_cleaned['ALLERGIES'].fillna('None', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAERS_ID             0\n",
      "RECVDATE             0\n",
      "STATE                0\n",
      "AGE_YRS              0\n",
      "SEX                  0\n",
      "SYMPTOM_TEXT         0\n",
      "DIED                 0\n",
      "DATEDIED        724374\n",
      "L_THREAT             0\n",
      "HOSPITAL             0\n",
      "DISABLE              0\n",
      "RECOVD               0\n",
      "VAX_DATE             0\n",
      "ONSET_DATE           0\n",
      "PRIOR_VAX            0\n",
      "BIRTH_DEFECT         0\n",
      "ALLERGIES            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing PRIOR_VAX with 'Unknown'\n",
    "vaers_data_cleaned['PRIOR_VAX'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Fill missing ALLERGIES with 'None'\n",
    "vaers_data_cleaned['ALLERGIES'].fillna('None', inplace=True)\n",
    "\n",
    "# Optionally drop rows with missing VAX_DATE or ONSET_DATE if time-based analysis is important\n",
    "vaers_data_cleaned = vaers_data_cleaned.dropna(subset=['VAX_DATE', 'ONSET_DATE'])\n",
    "\n",
    "# Verify the remaining missing values\n",
    "print(vaers_data_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAERS_ID             0\n",
      "RECVDATE             0\n",
      "STATE                0\n",
      "AGE_YRS              0\n",
      "SEX                  0\n",
      "SYMPTOM_TEXT         0\n",
      "DIED                 0\n",
      "DATEDIED        724374\n",
      "L_THREAT             0\n",
      "HOSPITAL             0\n",
      "DISABLE              0\n",
      "RECOVD               0\n",
      "VAX_DATE             0\n",
      "ONSET_DATE           0\n",
      "PRIOR_VAX            0\n",
      "BIRTH_DEFECT         0\n",
      "ALLERGIES            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fix for PRIOR_VAX: Directly assign the modified column back to the DataFrame\n",
    "vaers_data_cleaned['PRIOR_VAX'] = vaers_data_cleaned['PRIOR_VAX'].fillna('Unknown')\n",
    "\n",
    "# Fix for ALLERGIES: Directly assign the modified column back to the DataFrame\n",
    "vaers_data_cleaned['ALLERGIES'] = vaers_data_cleaned['ALLERGIES'].fillna('None')\n",
    "\n",
    "# Optionally drop rows with missing VAX_DATE or ONSET_DATE if time-based analysis is important\n",
    "vaers_data_cleaned = vaers_data_cleaned.dropna(subset=['VAX_DATE', 'ONSET_DATE'])\n",
    "\n",
    "# Verify the remaining missing values\n",
    "print(vaers_data_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DIED        DATEDIED\n",
      "0     0  Not applicable\n",
      "1     0  Not applicable\n",
      "2     0  Not applicable\n",
      "3     0  Not applicable\n",
      "4     0  Not applicable\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering: Ensure consistency between DIED and DATEDIED\n",
    "def correct_datedied(row):\n",
    "    if row['DIED'] == 1 and row['DATEDIED'] == 'Not applicable':\n",
    "        return 'Unknown death date'  # If they died but DATEDIED is missing\n",
    "    elif row['DIED'] == 0 and row['DATEDIED'] != 'Not applicable':\n",
    "        return 'Not applicable'  # If they didn't die but DATEDIED has a date\n",
    "    else:\n",
    "        return row['DATEDIED']\n",
    "\n",
    "# Apply the function to ensure consistency between DIED and DATEDIED\n",
    "vaers_data_cleaned['DATEDIED'] = vaers_data_cleaned.apply(correct_datedied, axis=1)\n",
    "\n",
    "# Verify the result\n",
    "print(vaers_data_cleaned[['DIED', 'DATEDIED']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DIED        DATEDIED\n",
      "0     0  Not applicable\n",
      "1     0  Not applicable\n",
      "2     0  Not applicable\n",
      "3     0  Not applicable\n",
      "4     0  Not applicable\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering: Ensure consistency between DIED and DATEDIED\n",
    "def correct_datedied(row):\n",
    "    if row['DIED'] == 1 and row['DATEDIED'] == 'Not applicable':\n",
    "        return 'Unknown death date'  # If they died but DATEDIED is missing or incorrect\n",
    "    elif row['DIED'] == 1 and pd.isna(row['DATEDIED']):\n",
    "        return 'Unknown death date'  # If DIED is 1 but DATEDIED is NaN\n",
    "    elif row['DIED'] == 0:\n",
    "        return 'Not applicable'  # If they didn't die, DATEDIED should be 'Not applicable'\n",
    "    else:\n",
    "        return row['DATEDIED']\n",
    "\n",
    "# Apply the function to ensure consistency between DIED and DATEDIED\n",
    "vaers_data_cleaned['DATEDIED'] = vaers_data_cleaned.apply(correct_datedied, axis=1)\n",
    "\n",
    "# Verify the result\n",
    "print(vaers_data_cleaned[['DIED', 'DATEDIED']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DIED    DATEDIED\n",
      "4259     1  12/25/2020\n",
      "5244     1  12/28/2020\n",
      "7421     1  12/29/2020\n",
      "7910     1  12/29/2020\n",
      "8656     1  12/20/2020\n",
      "8670     1  12/27/2020\n",
      "8725     1  12/26/2020\n",
      "8828     1  12/29/2020\n",
      "8909     1  12/30/2020\n",
      "8930     1  12/23/2020\n"
     ]
    }
   ],
   "source": [
    "# Check rows where DIED == 1 to see if DATEDIED is being handled correctly\n",
    "print(vaers_data_cleaned[vaers_data_cleaned['DIED'] == 1][['DIED', 'DATEDIED']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 735849 entries, 0 to 1012886\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   VAERS_ID      735849 non-null  int64         \n",
      " 1   RECVDATE      735849 non-null  datetime64[ns]\n",
      " 2   STATE         735849 non-null  object        \n",
      " 3   AGE_YRS       735849 non-null  float64       \n",
      " 4   SEX           735849 non-null  int64         \n",
      " 5   SYMPTOM_TEXT  735849 non-null  object        \n",
      " 6   DIED          735849 non-null  int64         \n",
      " 7   DATEDIED      735849 non-null  object        \n",
      " 8   L_THREAT      735849 non-null  int64         \n",
      " 9   HOSPITAL      735849 non-null  int64         \n",
      " 10  DISABLE       735849 non-null  int64         \n",
      " 11  RECOVD        735849 non-null  int64         \n",
      " 12  VAX_DATE      735849 non-null  datetime64[ns]\n",
      " 13  ONSET_DATE    735849 non-null  datetime64[ns]\n",
      " 14  PRIOR_VAX     735849 non-null  object        \n",
      " 15  BIRTH_DEFECT  735849 non-null  int64         \n",
      " 16  ALLERGIES     735849 non-null  object        \n",
      "dtypes: datetime64[ns](3), float64(1), int64(8), object(5)\n",
      "memory usage: 101.1+ MB\n"
     ]
    }
   ],
   "source": [
    "vaers_data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for DATEDIED after feature engineering:\n",
      "DATEDIED\n",
      "Not applicable        723985\n",
      "Unknown death date       389\n",
      "04/01/2021                46\n",
      "03/05/2021                46\n",
      "02/01/2021                44\n",
      "                       ...  \n",
      "04/17/2022                 1\n",
      "04/23/2022                 1\n",
      "04/26/2023                 1\n",
      "10/23/2023                 1\n",
      "10/16/2023                 1\n",
      "Name: count, Length: 1087, dtype: int64\n",
      "\n",
      "Data types after converting DATEDIED to datetime:\n",
      "VAERS_ID                 int64\n",
      "RECVDATE        datetime64[ns]\n",
      "STATE                   object\n",
      "AGE_YRS                float64\n",
      "SEX                      int64\n",
      "SYMPTOM_TEXT            object\n",
      "DIED                     int64\n",
      "DATEDIED        datetime64[ns]\n",
      "L_THREAT                 int64\n",
      "HOSPITAL                 int64\n",
      "DISABLE                  int64\n",
      "RECOVD                   int64\n",
      "VAX_DATE        datetime64[ns]\n",
      "ONSET_DATE      datetime64[ns]\n",
      "PRIOR_VAX               object\n",
      "BIRTH_DEFECT             int64\n",
      "ALLERGIES               object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sifre\\AppData\\Local\\Temp\\ipykernel_18368\\2429389554.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  vaers_data_cleaned['DATEDIED'] = pd.to_datetime(vaers_data_cleaned['DATEDIED'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# 1. Check the distribution of values in `DATEDIED` after feature engineering\n",
    "datedied_counts = vaers_data_cleaned['DATEDIED'].value_counts(dropna=False)\n",
    "print(\"Value counts for DATEDIED after feature engineering:\")\n",
    "print(datedied_counts)\n",
    "\n",
    "# 2. Convert only the valid dates in `DATEDIED` to datetime\n",
    "vaers_data_cleaned['DATEDIED'] = pd.to_datetime(vaers_data_cleaned['DATEDIED'], errors='coerce')\n",
    "\n",
    "# Verify the conversion and check the types\n",
    "print(\"\\nData types after converting DATEDIED to datetime:\")\n",
    "print(vaers_data_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for DATEDIED after handling 'Unknown death date':\n",
      "724374\n",
      "\n",
      "Final data types:\n",
      "VAERS_ID                 int64\n",
      "RECVDATE        datetime64[ns]\n",
      "STATE                   object\n",
      "AGE_YRS                float64\n",
      "SEX                      int64\n",
      "SYMPTOM_TEXT            object\n",
      "DIED                     int64\n",
      "DATEDIED        datetime64[ns]\n",
      "L_THREAT                 int64\n",
      "HOSPITAL                 int64\n",
      "DISABLE                  int64\n",
      "RECOVD                   int64\n",
      "VAX_DATE        datetime64[ns]\n",
      "ONSET_DATE      datetime64[ns]\n",
      "PRIOR_VAX               object\n",
      "BIRTH_DEFECT             int64\n",
      "ALLERGIES               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Replace \"Unknown death date\" with NaT\n",
    "vaers_data_cleaned['DATEDIED'] = vaers_data_cleaned['DATEDIED'].replace(\"Unknown death date\", pd.NaT)\n",
    "\n",
    "# Convert the remaining valid date entries to datetime, ensuring non-date values remain as NaT\n",
    "vaers_data_cleaned['DATEDIED'] = pd.to_datetime(vaers_data_cleaned['DATEDIED'], errors='coerce')\n",
    "\n",
    "# Verify the final data types and counts of NaT\n",
    "print(\"Value counts for DATEDIED after handling 'Unknown death date':\")\n",
    "print(vaers_data_cleaned['DATEDIED'].isnull().sum())\n",
    "\n",
    "# Check the final data types\n",
    "print(\"\\nFinal data types:\")\n",
    "print(vaers_data_cleaned.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sifre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sifre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sifre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vaers_data_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_text\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Apply the cleaning function to the SYMPTOM_TEXT column\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m vaers_data_cleaned[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSYMPTOM_TEXT_CLEANED\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mvaers_data_cleaned\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSYMPTOM_TEXT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(clean_symptom_text)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Check the cleaned text\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(vaers_data_cleaned[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSYMPTOM_TEXT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSYMPTOM_TEXT_CLEANED\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vaers_data_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download stopwords and tokenizer resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean symptom text\n",
    "def clean_symptom_text(text):\n",
    "    # 1. Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 3. Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # 4. Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # 5. Lemmatize words (get base form)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Join the cleaned words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function to the SYMPTOM_TEXT column\n",
    "vaers_data_cleaned['SYMPTOM_TEXT_CLEANED'] = vaers_data_cleaned['SYMPTOM_TEXT'].apply(clean_symptom_text)\n",
    "\n",
    "# Check the cleaned text\n",
    "print(vaers_data_cleaned[['SYMPTOM_TEXT', 'SYMPTOM_TEXT_CLEANED']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sifre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sifre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sifre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')         # Tokenizer data\n",
    "nltk.download('stopwords')     # Stopwords data\n",
    "nltk.download('wordnet')       # WordNet for lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sifre/nltk_data'\n    - 'c:\\\\Users\\\\sifre\\\\anaconda3\\\\envs\\\\VAC\\\\nltk_data'\n    - 'c:\\\\Users\\\\sifre\\\\anaconda3\\\\envs\\\\VAC\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\sifre\\\\anaconda3\\\\envs\\\\VAC\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sifre\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:/Users/sifre/AppData/Roaming/nltk_data'\n    - 'C:/Users/sifre/AppData/Roaming/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_text\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Apply the function to the symptom column\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m vaers_data_cleaned[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSYMPTOM_TEXT_CLEANED\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mvaers_data_cleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSYMPTOM_TEXT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# View cleaned text\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(vaers_data_cleaned[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSYMPTOM_TEXT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSYMPTOM_TEXT_CLEANED\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\pandas\\core\\series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[49], line 17\u001b[0m, in \u001b[0;36mclean_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     14\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, text) \u001b[38;5;66;03m# Remove numbers\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Tokenization\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Remove stopwords\u001b[39;00m\n\u001b[0;32m     20\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    145\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[1;32mc:\\Users\\sifre\\anaconda3\\envs\\VAC\\lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sifre/nltk_data'\n    - 'c:\\\\Users\\\\sifre\\\\anaconda3\\\\envs\\\\VAC\\\\nltk_data'\n    - 'c:\\\\Users\\\\sifre\\\\anaconda3\\\\envs\\\\VAC\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\sifre\\\\anaconda3\\\\envs\\\\VAC\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sifre\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:/Users/sifre/AppData/Roaming/nltk_data'\n    - 'C:/Users/sifre/AppData/Roaming/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Preprocessing function to clean and standardize text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text) # Remove numbers\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function to the symptom column\n",
    "vaers_data_cleaned['SYMPTOM_TEXT_CLEANED'] = vaers_data_cleaned['SYMPTOM_TEXT'].apply(clean_text)\n",
    "\n",
    "# View cleaned text\n",
    "print(vaers_data_cleaned[['SYMPTOM_TEXT', 'SYMPTOM_TEXT_CLEANED']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polyfuzzNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading polyfuzz-0.4.2-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from polyfuzz) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from polyfuzz) (1.13.1)\n",
      "Requirement already satisfied: pandas>=0.25.3 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from polyfuzz) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from polyfuzz) (4.66.5)\n",
      "Requirement already satisfied: joblib>=0.14.0 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from polyfuzz) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from polyfuzz) (3.9.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from polyfuzz) (0.13.2)\n",
      "Collecting rapidfuzz>=0.13.1 (from polyfuzz)\n",
      "  Downloading rapidfuzz-3.10.0-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from polyfuzz) (1.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from matplotlib>=3.2.2->polyfuzz) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from matplotlib>=3.2.2->polyfuzz) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from matplotlib>=3.2.2->polyfuzz) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from matplotlib>=3.2.2->polyfuzz) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from matplotlib>=3.2.2->polyfuzz) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from matplotlib>=3.2.2->polyfuzz) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from matplotlib>=3.2.2->polyfuzz) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from matplotlib>=3.2.2->polyfuzz) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from matplotlib>=3.2.2->polyfuzz) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from pandas>=0.25.3->polyfuzz) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from pandas>=0.25.3->polyfuzz) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from scikit-learn>=0.22.2.post1->polyfuzz) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from tqdm>=4.41.1->polyfuzz) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->polyfuzz) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sifre\\anaconda3\\envs\\vac\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->polyfuzz) (1.16.0)\n",
      "Downloading polyfuzz-0.4.2-py2.py3-none-any.whl (36 kB)\n",
      "Downloading rapidfuzz-3.10.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.8/1.6 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, polyfuzz\n",
      "Successfully installed polyfuzz-0.4.2 rapidfuzz-3.10.0\n"
     ]
    }
   ],
   "source": [
    "pip install polyfuzz\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
